* 
* ==> Audit <==
* |---------|-----------------|----------|----------|---------|----------------------|----------------------|
| Command |      Args       | Profile  |   User   | Version |      Start Time      |       End Time       |
|---------|-----------------|----------|----------|---------|----------------------|----------------------|
| start   |                 | minikube | juhaszjd | v1.31.2 | 17 Sep 23 10:57 CEST | 17 Sep 23 10:58 CEST |
| start   | --driver docker | minikube | juhaszjd | v1.31.2 | 17 Sep 23 10:59 CEST |                      |
| delete  |                 | minikube | juhaszjd | v1.31.2 | 17 Sep 23 11:00 CEST | 17 Sep 23 11:00 CEST |
| start   | --driver docker | minikube | juhaszjd | v1.31.2 | 17 Sep 23 11:00 CEST | 17 Sep 23 11:01 CEST |
| ip      |                 | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:21 CEST | 17 Sep 23 13:21 CEST |
| ip      |                 | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:32 CEST | 17 Sep 23 13:32 CEST |
| stop    |                 | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:32 CEST | 17 Sep 23 13:32 CEST |
| start   | --driver docker | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:33 CEST |                      |
| start   | --driver docker | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:34 CEST | 17 Sep 23 13:34 CEST |
| ip      |                 | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:35 CEST | 17 Sep 23 13:35 CEST |
| service | webapp-service  | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:36 CEST |                      |
| service | webapp-service  | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:38 CEST |                      |
| service | webapp-service  | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:38 CEST |                      |
| service | webapp-service  | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:38 CEST |                      |
| service | webapp-service  | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:41 CEST |                      |
| service | webapp-service  | minikube | juhaszjd | v1.31.2 | 17 Sep 23 13:43 CEST |                      |
|---------|-----------------|----------|----------|---------|----------------------|----------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/09/17 13:34:13
Running on machine: 192
Binary: Built with gc go1.21.0 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0917 13:34:13.214280   88341 out.go:296] Setting OutFile to fd 1 ...
I0917 13:34:13.214859   88341 out.go:348] isatty.IsTerminal(1) = true
I0917 13:34:13.214861   88341 out.go:309] Setting ErrFile to fd 2...
I0917 13:34:13.214864   88341 out.go:348] isatty.IsTerminal(2) = true
I0917 13:34:13.215216   88341 root.go:338] Updating PATH: /Users/juhaszjd/.minikube/bin
I0917 13:34:13.217123   88341 out.go:303] Setting JSON to false
I0917 13:34:13.236248   88341 start.go:128] hostinfo: {"hostname":"192.168.0.200","uptime":173174,"bootTime":1694777279,"procs":376,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"13.2.1","kernelVersion":"22.3.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"88dcc4b4-691a-532f-b38c-0bbaab3edb3d"}
W0917 13:34:13.236320   88341 start.go:136] gopshost.Virtualization returned error: not implemented yet
I0917 13:34:13.245829   88341 out.go:177] üòÑ  minikube v1.31.2 on Darwin 13.2.1 (arm64)
I0917 13:34:13.253551   88341 notify.go:220] Checking for updates...
I0917 13:34:13.253815   88341 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I0917 13:34:13.254930   88341 driver.go:373] Setting default libvirt URI to qemu:///system
I0917 13:34:13.343874   88341 docker.go:121] docker version: linux-24.0.6:Docker Desktop 4.23.0 (120376)
I0917 13:34:13.344303   88341 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0917 13:34:13.700569   88341 info.go:266] docker info: {ID:65d9ccce-0d07-477b-a139-b07a2fa818b0 Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:1 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:47 OomKillDisable:false NGoroutines:75 SystemTime:2023-09-17 11:34:13.681763421 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:14 KernelVersion:6.3.13-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4123820032 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:24.0.6 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:8165feabfdfe38c65b599c4993d227328c231fca Expected:8165feabfdfe38c65b599c4993d227328c231fca} RuncCommit:{ID:v1.1.8-0-g82f18fe Expected:v1.1.8-0-g82f18fe} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined name=cgroupns] ProductLicense: Warnings:[WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/juhaszjd/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.11.2-desktop.4] map[Name:compose Path:/Users/juhaszjd/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.21.0-desktop.1] map[Name:dev Path:/Users/juhaszjd/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/Users/juhaszjd/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.20] map[Name:init Path:/Users/juhaszjd/.docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.7] map[Name:sbom Path:/Users/juhaszjd/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/juhaszjd/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/Users/juhaszjd/.docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Command line tool for Docker Scout Vendor:Docker Inc. Version:0.24.1]] Warnings:<nil>}}
I0917 13:34:13.707553   88341 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0917 13:34:13.711555   88341 start.go:298] selected driver: docker
I0917 13:34:13.711558   88341 start.go:902] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0917 13:34:13.711598   88341 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0917 13:34:13.711862   88341 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0917 13:34:13.823587   88341 info.go:266] docker info: {ID:65d9ccce-0d07-477b-a139-b07a2fa818b0 Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:1 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:47 OomKillDisable:false NGoroutines:75 SystemTime:2023-09-17 11:34:13.805109296 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:14 KernelVersion:6.3.13-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4123820032 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:24.0.6 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:8165feabfdfe38c65b599c4993d227328c231fca Expected:8165feabfdfe38c65b599c4993d227328c231fca} RuncCommit:{ID:v1.1.8-0-g82f18fe Expected:v1.1.8-0-g82f18fe} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined name=cgroupns] ProductLicense: Warnings:[WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/juhaszjd/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.11.2-desktop.4] map[Name:compose Path:/Users/juhaszjd/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.21.0-desktop.1] map[Name:dev Path:/Users/juhaszjd/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/Users/juhaszjd/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.20] map[Name:init Path:/Users/juhaszjd/.docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v0.1.0-beta.7] map[Name:sbom Path:/Users/juhaszjd/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:/Users/juhaszjd/.docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.26.0] map[Name:scout Path:/Users/juhaszjd/.docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Command line tool for Docker Scout Vendor:Docker Inc. Version:0.24.1]] Warnings:<nil>}}
I0917 13:34:13.824484   88341 cni.go:84] Creating CNI manager for ""
I0917 13:34:13.824503   88341 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0917 13:34:13.824510   88341 start_flags.go:319] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0917 13:34:13.827965   88341 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0917 13:34:13.835842   88341 cache.go:122] Beginning downloading kic base image for docker with docker
I0917 13:34:13.839847   88341 out.go:177] üöú  Pulling base image ...
I0917 13:34:13.848176   88341 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon
I0917 13:34:13.848329   88341 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I0917 13:34:13.848361   88341 preload.go:148] Found local preload: /Users/juhaszjd/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4
I0917 13:34:13.848755   88341 cache.go:57] Caching tarball of preloaded images
I0917 13:34:13.849588   88341 preload.go:174] Found /Users/juhaszjd/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I0917 13:34:13.849640   88341 cache.go:60] Finished verifying existence of preloaded tar for  v1.27.4 on docker
I0917 13:34:13.849839   88341 profile.go:148] Saving config to /Users/juhaszjd/.minikube/profiles/minikube/config.json ...
I0917 13:34:13.895121   88341 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 in local docker daemon, skipping pull
I0917 13:34:13.895132   88341 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 exists in daemon, skipping load
I0917 13:34:13.895360   88341 cache.go:195] Successfully downloaded all kic artifacts
I0917 13:34:13.895950   88341 start.go:365] acquiring machines lock for minikube: {Name:mk400f91c56c67b1ae0fdd7e8755012536ccbda4 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0917 13:34:13.896022   88341 start.go:369] acquired machines lock for "minikube" in 48.5¬µs
I0917 13:34:13.896052   88341 start.go:96] Skipping create...Using existing machine configuration
I0917 13:34:13.896054   88341 fix.go:54] fixHost starting: 
I0917 13:34:13.896210   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:13.941476   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:13.941518   88341 fix.go:102] recreateIfNeeded on minikube: state= err=unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:13.941530   88341 fix.go:107] machineExists: false. err=machine does not exist
I0917 13:34:13.949898   88341 out.go:177] ü§∑  docker "minikube" container is missing, will recreate.
I0917 13:34:13.953072   88341 delete.go:124] DEMOLISHING minikube ...
I0917 13:34:13.953161   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:13.994480   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
W0917 13:34:13.994530   88341 stop.go:75] unable to get state: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:13.994539   88341 delete.go:128] stophost failed (probably ok): ssh power off: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:13.994796   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:14.035698   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:14.035750   88341 delete.go:82] Unable to get host status for minikube, assuming it has already been deleted: state: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:14.035803   88341 cli_runner.go:164] Run: docker container inspect -f {{.Id}} minikube
W0917 13:34:14.074515   88341 cli_runner.go:211] docker container inspect -f {{.Id}} minikube returned with exit code 1
I0917 13:34:14.074535   88341 kic.go:367] could not find the container minikube to remove it. will try anyways
I0917 13:34:14.074607   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:14.116538   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
W0917 13:34:14.116571   88341 oci.go:84] error getting container status, will try to delete anyways: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:14.116625   88341 cli_runner.go:164] Run: docker exec --privileged -t minikube /bin/bash -c "sudo init 0"
W0917 13:34:14.157675   88341 cli_runner.go:211] docker exec --privileged -t minikube /bin/bash -c "sudo init 0" returned with exit code 1
I0917 13:34:14.157693   88341 oci.go:647] error shutdown minikube: docker exec --privileged -t minikube /bin/bash -c "sudo init 0": exit status 1
stdout:

stderr:
Error response from daemon: No such container: minikube
I0917 13:34:15.159245   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:15.230965   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:15.231471   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:15.231477   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:15.231509   88341 retry.go:31] will retry after 449.375917ms: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:15.682192   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:15.739935   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:15.739969   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:15.739974   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:15.739992   88341 retry.go:31] will retry after 721.792359ms: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:16.463255   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:16.540242   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:16.540300   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:16.540304   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:16.540325   88341 retry.go:31] will retry after 1.298883484s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:17.840773   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:17.918242   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:17.918282   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:17.918289   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:17.918321   88341 retry.go:31] will retry after 2.319452654s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:20.238983   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:20.305355   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:20.305411   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:20.305431   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:20.305457   88341 retry.go:31] will retry after 2.585880761s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:22.893996   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:22.969781   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:22.969821   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:22.969830   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:22.969851   88341 retry.go:31] will retry after 3.367361715s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:26.338548   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:26.417042   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:26.417094   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:26.417100   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:26.417124   88341 retry.go:31] will retry after 5.737432838s: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:32.155216   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:32.235999   88341 cli_runner.go:211] docker container inspect minikube --format={{.State.Status}} returned with exit code 1
I0917 13:34:32.236048   88341 oci.go:659] temporary error verifying shutdown: unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
I0917 13:34:32.236054   88341 oci.go:661] temporary error: container minikube status is  but expect it to be exited
I0917 13:34:32.236082   88341 oci.go:88] couldn't shut down minikube (might be okay): verify shutdown: couldn't verify container is exited. %!v(MISSING): unknown state "minikube": docker container inspect minikube --format={{.State.Status}}: exit status 1
stdout:


stderr:
Error response from daemon: No such container: minikube
 
I0917 13:34:32.236148   88341 cli_runner.go:164] Run: docker rm -f -v minikube
I0917 13:34:32.285749   88341 cli_runner.go:164] Run: docker container inspect -f {{.Id}} minikube
W0917 13:34:32.328966   88341 cli_runner.go:211] docker container inspect -f {{.Id}} minikube returned with exit code 1
I0917 13:34:32.329057   88341 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0917 13:34:32.375004   88341 cli_runner.go:164] Run: docker network rm minikube
I0917 13:34:32.503672   88341 fix.go:114] Sleeping 1 second for extra luck!
I0917 13:34:33.504852   88341 start.go:125] createHost starting for "" (driver="docker")
I0917 13:34:33.509925   88341 out.go:204] üî•  Creating docker container (CPUs=2, Memory=2200MB) ...
I0917 13:34:33.510701   88341 start.go:159] libmachine.API.Create for "minikube" (driver="docker")
I0917 13:34:33.511090   88341 client.go:168] LocalClient.Create starting
I0917 13:34:33.512606   88341 main.go:141] libmachine: Reading certificate data from /Users/juhaszjd/.minikube/certs/ca.pem
I0917 13:34:33.512922   88341 main.go:141] libmachine: Decoding PEM data...
I0917 13:34:33.512975   88341 main.go:141] libmachine: Parsing certificate...
I0917 13:34:33.514133   88341 main.go:141] libmachine: Reading certificate data from /Users/juhaszjd/.minikube/certs/cert.pem
I0917 13:34:33.514353   88341 main.go:141] libmachine: Decoding PEM data...
I0917 13:34:33.514382   88341 main.go:141] libmachine: Parsing certificate...
I0917 13:34:33.515520   88341 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0917 13:34:33.591390   88341 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0917 13:34:33.591473   88341 network_create.go:281] running [docker network inspect minikube] to gather additional debugging logs...
I0917 13:34:33.591487   88341 cli_runner.go:164] Run: docker network inspect minikube
W0917 13:34:33.631577   88341 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0917 13:34:33.631593   88341 network_create.go:284] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error response from daemon: network minikube not found
I0917 13:34:33.631606   88341 network_create.go:286] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error response from daemon: network minikube not found

** /stderr **
I0917 13:34:33.631661   88341 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0917 13:34:33.671584   88341 network.go:209] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 IsPrivate:true Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:} reservation:0x14000521e80}
I0917 13:34:33.671774   88341 network_create.go:123] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 65535 ...
I0917 13:34:33.671821   88341 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=65535 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0917 13:34:33.758517   88341 network_create.go:107] docker network minikube 192.168.49.0/24 created
I0917 13:34:33.759000   88341 kic.go:117] calculated static IP "192.168.49.2" for the "minikube" container
I0917 13:34:33.759081   88341 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0917 13:34:33.797870   88341 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0917 13:34:33.836824   88341 oci.go:103] Successfully created a docker volume minikube
I0917 13:34:33.836943   88341 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -d /var/lib
I0917 13:34:34.474825   88341 oci.go:107] Successfully prepared a docker volume minikube
I0917 13:34:34.474873   88341 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I0917 13:34:34.474903   88341 kic.go:190] Starting extracting preloaded images to volume ...
I0917 13:34:34.475419   88341 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v /Users/juhaszjd/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -I lz4 -xf /preloaded.tar -C /extractDir
I0917 13:34:39.318229   88341 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v /Users/juhaszjd/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.27.4-docker-overlay2-arm64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 -I lz4 -xf /preloaded.tar -C /extractDir: (4.842885667s)
I0917 13:34:39.318845   88341 kic.go:199] duration metric: took 4.844146 seconds to extract preloaded images to volume
I0917 13:34:39.319355   88341 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0917 13:34:39.681687   88341 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631
I0917 13:34:39.967229   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0917 13:34:40.019471   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0917 13:34:40.062365   88341 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0917 13:34:40.144631   88341 oci.go:144] the created container "minikube" has a running status.
I0917 13:34:40.144853   88341 kic.go:221] Creating ssh key for kic: /Users/juhaszjd/.minikube/machines/minikube/id_rsa...
I0917 13:34:40.678730   88341 kic_runner.go:191] docker (temp): /Users/juhaszjd/.minikube/machines/minikube/id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0917 13:34:40.765392   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0917 13:34:40.822702   88341 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0917 13:34:40.822719   88341 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0917 13:34:40.902028   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0917 13:34:40.943932   88341 machine.go:88] provisioning docker machine ...
I0917 13:34:40.944744   88341 ubuntu.go:169] provisioning hostname "minikube"
I0917 13:34:40.945592   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:40.983976   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:40.988869   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:40.988880   88341 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0917 13:34:41.114871   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0917 13:34:41.115233   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:41.152625   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:41.152911   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:41.152918   88341 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0917 13:34:41.257057   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0917 13:34:41.257072   88341 ubuntu.go:175] set auth options {CertDir:/Users/juhaszjd/.minikube CaCertPath:/Users/juhaszjd/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/juhaszjd/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/juhaszjd/.minikube/machines/server.pem ServerKeyPath:/Users/juhaszjd/.minikube/machines/server-key.pem ClientKeyPath:/Users/juhaszjd/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/juhaszjd/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/juhaszjd/.minikube}
I0917 13:34:41.257094   88341 ubuntu.go:177] setting up certificates
I0917 13:34:41.257477   88341 provision.go:83] configureAuth start
I0917 13:34:41.257706   88341 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0917 13:34:41.307791   88341 provision.go:138] copyHostCerts
I0917 13:34:41.308549   88341 exec_runner.go:144] found /Users/juhaszjd/.minikube/ca.pem, removing ...
I0917 13:34:41.308558   88341 exec_runner.go:203] rm: /Users/juhaszjd/.minikube/ca.pem
I0917 13:34:41.308651   88341 exec_runner.go:151] cp: /Users/juhaszjd/.minikube/certs/ca.pem --> /Users/juhaszjd/.minikube/ca.pem (1082 bytes)
I0917 13:34:41.308964   88341 exec_runner.go:144] found /Users/juhaszjd/.minikube/cert.pem, removing ...
I0917 13:34:41.308965   88341 exec_runner.go:203] rm: /Users/juhaszjd/.minikube/cert.pem
I0917 13:34:41.309008   88341 exec_runner.go:151] cp: /Users/juhaszjd/.minikube/certs/cert.pem --> /Users/juhaszjd/.minikube/cert.pem (1127 bytes)
I0917 13:34:41.309208   88341 exec_runner.go:144] found /Users/juhaszjd/.minikube/key.pem, removing ...
I0917 13:34:41.309209   88341 exec_runner.go:203] rm: /Users/juhaszjd/.minikube/key.pem
I0917 13:34:41.309246   88341 exec_runner.go:151] cp: /Users/juhaszjd/.minikube/certs/key.pem --> /Users/juhaszjd/.minikube/key.pem (1679 bytes)
I0917 13:34:41.309367   88341 provision.go:112] generating server cert: /Users/juhaszjd/.minikube/machines/server.pem ca-key=/Users/juhaszjd/.minikube/certs/ca.pem private-key=/Users/juhaszjd/.minikube/certs/ca-key.pem org=juhaszjd.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0917 13:34:41.420054   88341 provision.go:172] copyRemoteCerts
I0917 13:34:41.420253   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0917 13:34:41.420291   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:41.457039   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:41.539707   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/machines/server.pem --> /etc/docker/server.pem (1204 bytes)
I0917 13:34:41.556416   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0917 13:34:41.570086   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0917 13:34:41.584141   88341 provision.go:86] duration metric: configureAuth took 326.642625ms
I0917 13:34:41.584154   88341 ubuntu.go:193] setting minikube options for container-runtime
I0917 13:34:41.585257   88341 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I0917 13:34:41.585320   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:41.624995   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:41.625265   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:41.625272   88341 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0917 13:34:41.735078   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0917 13:34:41.735087   88341 ubuntu.go:71] root file system type: overlay
I0917 13:34:41.735540   88341 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0917 13:34:41.735618   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:41.773753   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:41.774021   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:41.774058   88341 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0917 13:34:41.889379   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0917 13:34:41.889697   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:41.932850   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:41.933140   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:41.933149   88341 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0917 13:34:42.435956   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2023-07-07 14:51:01.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2023-09-17 11:34:41.888140003 +0000
@@ -1,30 +1,32 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service time-set.target
-Wants=network-online.target containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
+Wants=network-online.target
 Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutStartSec=0
-RestartSec=2
-Restart=always
+Restart=on-failure
 
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +34,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0917 13:34:42.435969   88341 machine.go:91] provisioned docker machine in 1.492082459s
I0917 13:34:42.435973   88341 client.go:171] LocalClient.Create took 8.925293875s
I0917 13:34:42.436216   88341 start.go:167] duration metric: libmachine.API.Create for "minikube" took 8.925941042s
I0917 13:34:42.436221   88341 start.go:300] post-start starting for "minikube" (driver="docker")
I0917 13:34:42.436449   88341 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0917 13:34:42.436549   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0917 13:34:42.436583   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:42.474263   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:42.552469   88341 ssh_runner.go:195] Run: cat /etc/os-release
I0917 13:34:42.556065   88341 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0917 13:34:42.556077   88341 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0917 13:34:42.556082   88341 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0917 13:34:42.556084   88341 info.go:137] Remote host: Ubuntu 22.04.2 LTS
I0917 13:34:42.556089   88341 filesync.go:126] Scanning /Users/juhaszjd/.minikube/addons for local assets ...
I0917 13:34:42.556173   88341 filesync.go:126] Scanning /Users/juhaszjd/.minikube/files for local assets ...
I0917 13:34:42.556198   88341 start.go:303] post-start completed in 119.979875ms
I0917 13:34:42.556508   88341 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0917 13:34:42.593127   88341 profile.go:148] Saving config to /Users/juhaszjd/.minikube/profiles/minikube/config.json ...
I0917 13:34:42.593610   88341 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0917 13:34:42.593654   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:42.634431   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:42.712929   88341 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0917 13:34:42.715949   88341 start.go:128] duration metric: createHost completed in 9.211490708s
I0917 13:34:42.716253   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
W0917 13:34:42.753568   88341 fix.go:128] unexpected machine state, will restart: <nil>
I0917 13:34:42.753604   88341 machine.go:88] provisioning docker machine ...
I0917 13:34:42.753619   88341 ubuntu.go:169] provisioning hostname "minikube"
I0917 13:34:42.753697   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:42.789302   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:42.789588   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:42.789592   88341 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0917 13:34:42.907315   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0917 13:34:42.907407   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:42.945807   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:42.946108   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:42.946114   88341 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0917 13:34:43.051229   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0917 13:34:43.051247   88341 ubuntu.go:175] set auth options {CertDir:/Users/juhaszjd/.minikube CaCertPath:/Users/juhaszjd/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/juhaszjd/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/juhaszjd/.minikube/machines/server.pem ServerKeyPath:/Users/juhaszjd/.minikube/machines/server-key.pem ClientKeyPath:/Users/juhaszjd/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/juhaszjd/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/juhaszjd/.minikube}
I0917 13:34:43.051253   88341 ubuntu.go:177] setting up certificates
I0917 13:34:43.051256   88341 provision.go:83] configureAuth start
I0917 13:34:43.051315   88341 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0917 13:34:43.089614   88341 provision.go:138] copyHostCerts
I0917 13:34:43.089692   88341 exec_runner.go:144] found /Users/juhaszjd/.minikube/ca.pem, removing ...
I0917 13:34:43.089695   88341 exec_runner.go:203] rm: /Users/juhaszjd/.minikube/ca.pem
I0917 13:34:43.089761   88341 exec_runner.go:151] cp: /Users/juhaszjd/.minikube/certs/ca.pem --> /Users/juhaszjd/.minikube/ca.pem (1082 bytes)
I0917 13:34:43.089892   88341 exec_runner.go:144] found /Users/juhaszjd/.minikube/cert.pem, removing ...
I0917 13:34:43.089894   88341 exec_runner.go:203] rm: /Users/juhaszjd/.minikube/cert.pem
I0917 13:34:43.089932   88341 exec_runner.go:151] cp: /Users/juhaszjd/.minikube/certs/cert.pem --> /Users/juhaszjd/.minikube/cert.pem (1127 bytes)
I0917 13:34:43.090010   88341 exec_runner.go:144] found /Users/juhaszjd/.minikube/key.pem, removing ...
I0917 13:34:43.090012   88341 exec_runner.go:203] rm: /Users/juhaszjd/.minikube/key.pem
I0917 13:34:43.090041   88341 exec_runner.go:151] cp: /Users/juhaszjd/.minikube/certs/key.pem --> /Users/juhaszjd/.minikube/key.pem (1679 bytes)
I0917 13:34:43.090111   88341 provision.go:112] generating server cert: /Users/juhaszjd/.minikube/machines/server.pem ca-key=/Users/juhaszjd/.minikube/certs/ca.pem private-key=/Users/juhaszjd/.minikube/certs/ca-key.pem org=juhaszjd.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0917 13:34:43.246171   88341 provision.go:172] copyRemoteCerts
I0917 13:34:43.246227   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0917 13:34:43.246260   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:43.290195   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:43.390476   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0917 13:34:43.409911   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/machines/server.pem --> /etc/docker/server.pem (1204 bytes)
I0917 13:34:43.424563   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0917 13:34:43.438444   88341 provision.go:86] duration metric: configureAuth took 387.199334ms
I0917 13:34:43.438453   88341 ubuntu.go:193] setting minikube options for container-runtime
I0917 13:34:43.438591   88341 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I0917 13:34:43.438633   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:43.481100   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:43.481359   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:43.481363   88341 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0917 13:34:43.586759   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0917 13:34:43.586766   88341 ubuntu.go:71] root file system type: overlay
I0917 13:34:43.586836   88341 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0917 13:34:43.586913   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:43.627361   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:43.627662   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:43.627698   88341 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0917 13:34:43.742405   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0917 13:34:43.742482   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:43.780417   88341 main.go:141] libmachine: Using SSH client type: native
I0917 13:34:43.780691   88341 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x10516f730] 0x105171ea0 <nil>  [] 0s} 127.0.0.1 55150 <nil> <nil>}
I0917 13:34:43.780699   88341 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0917 13:34:43.892238   88341 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0917 13:34:43.892250   88341 machine.go:91] provisioned docker machine in 1.138695041s
I0917 13:34:43.892254   88341 start.go:300] post-start starting for "minikube" (driver="docker")
I0917 13:34:43.892260   88341 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0917 13:34:43.892371   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0917 13:34:43.892423   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:43.935151   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:44.017090   88341 ssh_runner.go:195] Run: cat /etc/os-release
I0917 13:34:44.019575   88341 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0917 13:34:44.019586   88341 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0917 13:34:44.019590   88341 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0917 13:34:44.019593   88341 info.go:137] Remote host: Ubuntu 22.04.2 LTS
I0917 13:34:44.019597   88341 filesync.go:126] Scanning /Users/juhaszjd/.minikube/addons for local assets ...
I0917 13:34:44.019689   88341 filesync.go:126] Scanning /Users/juhaszjd/.minikube/files for local assets ...
I0917 13:34:44.019715   88341 start.go:303] post-start completed in 127.46425ms
I0917 13:34:44.019760   88341 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0917 13:34:44.019798   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:44.056798   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:44.134454   88341 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0917 13:34:44.137483   88341 fix.go:56] fixHost completed within 30.242842416s
I0917 13:34:44.137492   88341 start.go:83] releasing machines lock for "minikube", held for 30.242882041s
I0917 13:34:44.137793   88341 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0917 13:34:44.174945   88341 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0917 13:34:44.174985   88341 ssh_runner.go:195] Run: cat /version.json
I0917 13:34:44.175028   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:44.175733   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:44.219385   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:44.219446   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:44.666747   88341 ssh_runner.go:195] Run: systemctl --version
I0917 13:34:44.675256   88341 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0917 13:34:44.679155   88341 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0917 13:34:44.700045   88341 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0917 13:34:44.700277   88341 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0917 13:34:44.721069   88341 cni.go:262] disabled [/etc/cni/net.d/100-crio-bridge.conf, /etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I0917 13:34:44.721297   88341 start.go:466] detecting cgroup driver to use...
I0917 13:34:44.721310   88341 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0917 13:34:44.722729   88341 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0917 13:34:44.734285   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0917 13:34:44.742617   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0917 13:34:44.749524   88341 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0917 13:34:44.749584   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0917 13:34:44.756013   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0917 13:34:44.762638   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0917 13:34:44.769423   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0917 13:34:44.775950   88341 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0917 13:34:44.783229   88341 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0917 13:34:44.789562   88341 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0917 13:34:44.795327   88341 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0917 13:34:44.800362   88341 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0917 13:34:44.857561   88341 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0917 13:34:44.920501   88341 start.go:466] detecting cgroup driver to use...
I0917 13:34:44.920515   88341 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0917 13:34:44.920697   88341 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0917 13:34:44.947534   88341 cruntime.go:276] skipping containerd shutdown because we are bound to it
I0917 13:34:44.947876   88341 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0917 13:34:44.957474   88341 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0917 13:34:44.970703   88341 ssh_runner.go:195] Run: which cri-dockerd
I0917 13:34:44.973425   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0917 13:34:44.979537   88341 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0917 13:34:44.991311   88341 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0917 13:34:45.047365   88341 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0917 13:34:45.103234   88341 docker.go:535] configuring docker to use "cgroupfs" as cgroup driver...
I0917 13:34:45.105358   88341 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (144 bytes)
I0917 13:34:45.116595   88341 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0917 13:34:45.169430   88341 ssh_runner.go:195] Run: sudo systemctl restart docker
I0917 13:34:45.310257   88341 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0917 13:34:45.363425   88341 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0917 13:34:45.418870   88341 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0917 13:34:45.472356   88341 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0917 13:34:45.526614   88341 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0917 13:34:45.553679   88341 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0917 13:34:45.608314   88341 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0917 13:34:45.734301   88341 start.go:513] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0917 13:34:45.734679   88341 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0917 13:34:45.737854   88341 start.go:534] Will wait 60s for crictl version
I0917 13:34:45.737916   88341 ssh_runner.go:195] Run: which crictl
I0917 13:34:45.740219   88341 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0917 13:34:45.889403   88341 start.go:550] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.4
RuntimeApiVersion:  v1
I0917 13:34:45.889467   88341 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0917 13:34:45.965616   88341 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0917 13:34:45.985220   88341 out.go:204] üê≥  Preparing Kubernetes v1.27.4 on Docker 24.0.4 ...
I0917 13:34:45.985775   88341 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0917 13:34:46.123160   88341 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0917 13:34:46.123620   88341 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0917 13:34:46.126842   88341 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0917 13:34:46.134218   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0917 13:34:46.172147   88341 preload.go:132] Checking if preload exists for k8s version v1.27.4 and runtime docker
I0917 13:34:46.172200   88341 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0917 13:34:46.189216   88341 docker.go:636] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.27.4
registry.k8s.io/kube-scheduler:v1.27.4
registry.k8s.io/kube-controller-manager:v1.27.4
registry.k8s.io/kube-proxy:v1.27.4
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0917 13:34:46.189643   88341 docker.go:566] Images already preloaded, skipping extraction
I0917 13:34:46.190072   88341 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0917 13:34:46.201534   88341 docker.go:636] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.27.4
registry.k8s.io/kube-scheduler:v1.27.4
registry.k8s.io/kube-controller-manager:v1.27.4
registry.k8s.io/kube-proxy:v1.27.4
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/etcd:3.5.7-0
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0917 13:34:46.201730   88341 cache_images.go:84] Images are preloaded, skipping loading
I0917 13:34:46.201966   88341 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0917 13:34:46.359850   88341 cni.go:84] Creating CNI manager for ""
I0917 13:34:46.359856   88341 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0917 13:34:46.360098   88341 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0917 13:34:46.360117   88341 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.27.4 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0917 13:34:46.361273   88341 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.27.4
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0917 13:34:46.361681   88341 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.27.4/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0917 13:34:46.361766   88341 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.27.4
I0917 13:34:46.368579   88341 binaries.go:44] Found k8s binaries, skipping transfer
I0917 13:34:46.368639   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0917 13:34:46.373972   88341 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0917 13:34:46.383931   88341 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0917 13:34:46.393715   88341 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2091 bytes)
I0917 13:34:46.403705   88341 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0917 13:34:46.405974   88341 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0917 13:34:46.415852   88341 certs.go:56] Setting up /Users/juhaszjd/.minikube/profiles/minikube for IP: 192.168.49.2
I0917 13:34:46.415904   88341 certs.go:190] acquiring lock for shared ca certs: {Name:mkfd85785576324e209a72f091ba091054bde429 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0917 13:34:46.416824   88341 certs.go:199] skipping minikubeCA CA generation: /Users/juhaszjd/.minikube/ca.key
I0917 13:34:46.417156   88341 certs.go:199] skipping proxyClientCA CA generation: /Users/juhaszjd/.minikube/proxy-client-ca.key
I0917 13:34:46.417710   88341 certs.go:315] skipping minikube-user signed cert generation: /Users/juhaszjd/.minikube/profiles/minikube/client.key
I0917 13:34:46.417930   88341 certs.go:315] skipping minikube signed cert generation: /Users/juhaszjd/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0917 13:34:46.418103   88341 certs.go:315] skipping aggregator signed cert generation: /Users/juhaszjd/.minikube/profiles/minikube/proxy-client.key
I0917 13:34:46.418587   88341 certs.go:437] found cert: /Users/juhaszjd/.minikube/certs/Users/juhaszjd/.minikube/certs/ca-key.pem (1675 bytes)
I0917 13:34:46.418618   88341 certs.go:437] found cert: /Users/juhaszjd/.minikube/certs/Users/juhaszjd/.minikube/certs/ca.pem (1082 bytes)
I0917 13:34:46.418643   88341 certs.go:437] found cert: /Users/juhaszjd/.minikube/certs/Users/juhaszjd/.minikube/certs/cert.pem (1127 bytes)
I0917 13:34:46.418665   88341 certs.go:437] found cert: /Users/juhaszjd/.minikube/certs/Users/juhaszjd/.minikube/certs/key.pem (1679 bytes)
I0917 13:34:46.426060   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0917 13:34:46.440148   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0917 13:34:46.453677   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0917 13:34:46.467139   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0917 13:34:46.480655   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0917 13:34:46.493863   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0917 13:34:46.506560   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0917 13:34:46.521831   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0917 13:34:46.535974   88341 ssh_runner.go:362] scp /Users/juhaszjd/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0917 13:34:46.549756   88341 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (740 bytes)
I0917 13:34:46.560039   88341 ssh_runner.go:195] Run: openssl version
I0917 13:34:46.568811   88341 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0917 13:34:46.575170   88341 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0917 13:34:46.577612   88341 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Sep 17 08:58 /usr/share/ca-certificates/minikubeCA.pem
I0917 13:34:46.577643   88341 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0917 13:34:46.581927   88341 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0917 13:34:46.587554   88341 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0917 13:34:46.589681   88341 certs.go:353] certs directory doesn't exist, likely first start: ls /var/lib/minikube/certs/etcd: Process exited with status 2
stdout:

stderr:
ls: cannot access '/var/lib/minikube/certs/etcd': No such file or directory
I0917 13:34:46.589723   88341 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.40@sha256:8cadf23777709e43eca447c47a45f5a4635615129267ce025193040ec92a1631 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.27.4 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0}
I0917 13:34:46.589775   88341 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0917 13:34:46.600313   88341 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0917 13:34:46.605869   88341 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0917 13:34:46.611235   88341 kubeadm.go:226] ignoring SystemVerification for kubeadm because of docker driver
I0917 13:34:46.611278   88341 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0917 13:34:46.618752   88341 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0917 13:34:46.618945   88341 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.27.4:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0917 13:34:46.658887   88341 kubeadm.go:322] [init] Using Kubernetes version: v1.27.4
I0917 13:34:46.658972   88341 kubeadm.go:322] [preflight] Running pre-flight checks
I0917 13:34:46.814207   88341 kubeadm.go:322] [preflight] Pulling images required for setting up a Kubernetes cluster
I0917 13:34:46.814269   88341 kubeadm.go:322] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0917 13:34:46.814318   88341 kubeadm.go:322] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0917 13:34:46.977900   88341 kubeadm.go:322] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0917 13:34:46.987984   88341 out.go:204]     ‚ñ™ Generating certificates and keys ...
I0917 13:34:46.988128   88341 kubeadm.go:322] [certs] Using existing ca certificate authority
I0917 13:34:46.988165   88341 kubeadm.go:322] [certs] Using existing apiserver certificate and key on disk
I0917 13:34:47.229051   88341 kubeadm.go:322] [certs] Generating "apiserver-kubelet-client" certificate and key
I0917 13:34:47.281108   88341 kubeadm.go:322] [certs] Generating "front-proxy-ca" certificate and key
I0917 13:34:47.353222   88341 kubeadm.go:322] [certs] Generating "front-proxy-client" certificate and key
I0917 13:34:47.412325   88341 kubeadm.go:322] [certs] Generating "etcd/ca" certificate and key
I0917 13:34:47.509214   88341 kubeadm.go:322] [certs] Generating "etcd/server" certificate and key
I0917 13:34:47.509283   88341 kubeadm.go:322] [certs] etcd/server serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0917 13:34:47.556315   88341 kubeadm.go:322] [certs] Generating "etcd/peer" certificate and key
I0917 13:34:47.556372   88341 kubeadm.go:322] [certs] etcd/peer serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0917 13:34:47.643959   88341 kubeadm.go:322] [certs] Generating "etcd/healthcheck-client" certificate and key
I0917 13:34:47.828468   88341 kubeadm.go:322] [certs] Generating "apiserver-etcd-client" certificate and key
I0917 13:34:47.974846   88341 kubeadm.go:322] [certs] Generating "sa" key and public key
I0917 13:34:47.974877   88341 kubeadm.go:322] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0917 13:34:48.097851   88341 kubeadm.go:322] [kubeconfig] Writing "admin.conf" kubeconfig file
I0917 13:34:48.222442   88341 kubeadm.go:322] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0917 13:34:48.610179   88341 kubeadm.go:322] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0917 13:34:48.678325   88341 kubeadm.go:322] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0917 13:34:48.695964   88341 kubeadm.go:322] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0917 13:34:48.696450   88341 kubeadm.go:322] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0917 13:34:48.696469   88341 kubeadm.go:322] [kubelet-start] Starting the kubelet
I0917 13:34:48.761531   88341 kubeadm.go:322] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0917 13:34:48.765171   88341 out.go:204]     ‚ñ™ Booting up control plane ...
I0917 13:34:48.765260   88341 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-apiserver"
I0917 13:34:48.765294   88341 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0917 13:34:48.765330   88341 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-scheduler"
I0917 13:34:48.765369   88341 kubeadm.go:322] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0917 13:34:48.767199   88341 kubeadm.go:322] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
I0917 13:34:53.771426   88341 kubeadm.go:322] [apiclient] All control plane components are healthy after 5.002616 seconds
I0917 13:34:53.771582   88341 kubeadm.go:322] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0917 13:34:53.789369   88341 kubeadm.go:322] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0917 13:34:54.305247   88341 kubeadm.go:322] [upload-certs] Skipping phase. Please see --upload-certs
I0917 13:34:54.305393   88341 kubeadm.go:322] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0917 13:34:54.831684   88341 kubeadm.go:322] [bootstrap-token] Using token: rx6dch.8yyy9sidzmnqfp3a
I0917 13:34:54.837645   88341 out.go:204]     ‚ñ™ Configuring RBAC rules ...
I0917 13:34:54.838016   88341 kubeadm.go:322] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0917 13:34:54.843774   88341 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0917 13:34:54.857743   88341 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0917 13:34:54.864088   88341 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0917 13:34:54.870187   88341 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0917 13:34:54.875264   88341 kubeadm.go:322] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0917 13:34:54.886156   88341 kubeadm.go:322] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0917 13:34:55.091453   88341 kubeadm.go:322] [addons] Applied essential addon: CoreDNS
I0917 13:34:55.245886   88341 kubeadm.go:322] [addons] Applied essential addon: kube-proxy
I0917 13:34:55.246367   88341 kubeadm.go:322] 
I0917 13:34:55.246397   88341 kubeadm.go:322] Your Kubernetes control-plane has initialized successfully!
I0917 13:34:55.246399   88341 kubeadm.go:322] 
I0917 13:34:55.246443   88341 kubeadm.go:322] To start using your cluster, you need to run the following as a regular user:
I0917 13:34:55.246445   88341 kubeadm.go:322] 
I0917 13:34:55.246456   88341 kubeadm.go:322]   mkdir -p $HOME/.kube
I0917 13:34:55.246482   88341 kubeadm.go:322]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0917 13:34:55.246505   88341 kubeadm.go:322]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0917 13:34:55.246506   88341 kubeadm.go:322] 
I0917 13:34:55.246531   88341 kubeadm.go:322] Alternatively, if you are the root user, you can run:
I0917 13:34:55.246532   88341 kubeadm.go:322] 
I0917 13:34:55.246558   88341 kubeadm.go:322]   export KUBECONFIG=/etc/kubernetes/admin.conf
I0917 13:34:55.246587   88341 kubeadm.go:322] 
I0917 13:34:55.246621   88341 kubeadm.go:322] You should now deploy a pod network to the cluster.
I0917 13:34:55.246661   88341 kubeadm.go:322] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0917 13:34:55.246710   88341 kubeadm.go:322]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0917 13:34:55.246711   88341 kubeadm.go:322] 
I0917 13:34:55.246758   88341 kubeadm.go:322] You can now join any number of control-plane nodes by copying certificate authorities
I0917 13:34:55.246802   88341 kubeadm.go:322] and service account keys on each node and then running the following as root:
I0917 13:34:55.246804   88341 kubeadm.go:322] 
I0917 13:34:55.246861   88341 kubeadm.go:322]   kubeadm join control-plane.minikube.internal:8443 --token rx6dch.8yyy9sidzmnqfp3a \
I0917 13:34:55.246931   88341 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:4ff1779fbf57fd0278f001ba47c8b404c612df2c24f81a16b2177d23e64c3914 \
I0917 13:34:55.246951   88341 kubeadm.go:322] 	--control-plane 
I0917 13:34:55.246953   88341 kubeadm.go:322] 
I0917 13:34:55.246996   88341 kubeadm.go:322] Then you can join any number of worker nodes by running the following on each as root:
I0917 13:34:55.246998   88341 kubeadm.go:322] 
I0917 13:34:55.247042   88341 kubeadm.go:322] kubeadm join control-plane.minikube.internal:8443 --token rx6dch.8yyy9sidzmnqfp3a \
I0917 13:34:55.247094   88341 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:4ff1779fbf57fd0278f001ba47c8b404c612df2c24f81a16b2177d23e64c3914 
I0917 13:34:55.250159   88341 kubeadm.go:322] 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0917 13:34:55.250211   88341 kubeadm.go:322] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0917 13:34:55.250230   88341 cni.go:84] Creating CNI manager for ""
I0917 13:34:55.250261   88341 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0917 13:34:55.253608   88341 out.go:177] üîó  Configuring bridge CNI (Container Networking Interface) ...
I0917 13:34:55.260788   88341 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0917 13:34:55.276367   88341 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0917 13:34:55.290395   88341 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0917 13:34:55.290515   88341 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.27.4/kubectl label nodes minikube.k8s.io/version=v1.31.2 minikube.k8s.io/commit=fd7ecd9c4599bef9f04c0986c4a0187f98a4396e minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2023_09_17T13_34_55_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0917 13:34:55.290684   88341 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.27.4/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0917 13:34:55.385185   88341 kubeadm.go:1081] duration metric: took 94.538959ms to wait for elevateKubeSystemPrivileges.
I0917 13:34:55.385432   88341 ops.go:34] apiserver oom_adj: -16
I0917 13:34:55.398437   88341 kubeadm.go:406] StartCluster complete in 8.809122375s
I0917 13:34:55.398669   88341 settings.go:142] acquiring lock: {Name:mk7850520bbab063f8e4d0c60529a7d92fbed58d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0917 13:34:55.398775   88341 settings.go:150] Updating kubeconfig:  /Users/juhaszjd/.kube/config
I0917 13:34:55.402296   88341 lock.go:35] WriteFile acquiring /Users/juhaszjd/.kube/config: {Name:mk3a745c5b568b0f3050e7c625fa7bb4957f7c7e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0917 13:34:55.402679   88341 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.4/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0917 13:34:55.402961   88341 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.27.4
I0917 13:34:55.402740   88341 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false]
I0917 13:34:55.403187   88341 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0917 13:34:55.403188   88341 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0917 13:34:55.403306   88341 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W0917 13:34:55.403314   88341 addons.go:240] addon storage-provisioner should already be in state true
I0917 13:34:55.403322   88341 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0917 13:34:55.404009   88341 host.go:66] Checking if "minikube" exists ...
I0917 13:34:55.404165   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0917 13:34:55.404287   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0917 13:34:55.467586   88341 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0917 13:34:55.468047   88341 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0917 13:34:55.469236   88341 addons.go:231] Setting addon default-storageclass=true in "minikube"
W0917 13:34:55.470634   88341 addons.go:240] addon default-storageclass should already be in state true
I0917 13:34:55.470646   88341 host.go:66] Checking if "minikube" exists ...
I0917 13:34:55.470711   88341 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0917 13:34:55.470715   88341 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0917 13:34:55.470766   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:55.471078   88341 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0917 13:34:55.471165   88341 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.27.4 ContainerRuntime:docker ControlPlane:true Worker:true}
I0917 13:34:55.474738   88341 out.go:177] üîé  Verifying Kubernetes components...
I0917 13:34:55.482777   88341 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0917 13:34:55.483446   88341 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.27.4/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.65.254 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.27.4/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0917 13:34:55.501630   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0917 13:34:55.546887   88341 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0917 13:34:55.546901   88341 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0917 13:34:55.546991   88341 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0917 13:34:55.549162   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:55.562078   88341 api_server.go:52] waiting for apiserver process to appear ...
I0917 13:34:55.562132   88341 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0917 13:34:55.591176   88341 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55150 SSHKeyPath:/Users/juhaszjd/.minikube/machines/minikube/id_rsa Username:docker}
I0917 13:34:55.670072   88341 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0917 13:34:55.679973   88341 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.27.4/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0917 13:34:56.129049   88341 start.go:901] {"host.minikube.internal": 192.168.65.254} host record injected into CoreDNS's ConfigMap
I0917 13:34:56.129080   88341 api_server.go:72] duration metric: took 657.667417ms to wait for apiserver process to appear ...
I0917 13:34:56.129089   88341 api_server.go:88] waiting for apiserver healthz status ...
I0917 13:34:56.129108   88341 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:55154/healthz ...
I0917 13:34:56.134574   88341 api_server.go:279] https://127.0.0.1:55154/healthz returned 200:
ok
I0917 13:34:56.136153   88341 api_server.go:141] control plane version: v1.27.4
I0917 13:34:56.136164   88341 api_server.go:131] duration metric: took 7.070792ms to wait for apiserver health ...
I0917 13:34:56.136354   88341 system_pods.go:43] waiting for kube-system pods to appear ...
I0917 13:34:56.144986   88341 system_pods.go:59] 4 kube-system pods found
I0917 13:34:56.145015   88341 system_pods.go:61] "etcd-minikube" [ff473ff5-5b61-4efb-89d6-d87030af4ff7] Pending
I0917 13:34:56.145021   88341 system_pods.go:61] "kube-apiserver-minikube" [2a45efc0-1830-44b7-8aa0-6437d44ece87] Pending
I0917 13:34:56.145049   88341 system_pods.go:61] "kube-controller-manager-minikube" [a3634ac8-0329-452b-a1ba-0e85511b37b4] Pending
I0917 13:34:56.145058   88341 system_pods.go:61] "kube-scheduler-minikube" [87ba93b4-2542-417f-a4b5-e315a51df32d] Pending
I0917 13:34:56.145062   88341 system_pods.go:74] duration metric: took 8.704916ms to wait for pod list to return data ...
I0917 13:34:56.145067   88341 kubeadm.go:581] duration metric: took 673.660917ms to wait for : map[apiserver:true system_pods:true] ...
I0917 13:34:56.145267   88341 node_conditions.go:102] verifying NodePressure condition ...
I0917 13:34:56.147820   88341 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I0917 13:34:56.147829   88341 node_conditions.go:123] node cpu capacity is 4
I0917 13:34:56.148046   88341 node_conditions.go:105] duration metric: took 2.6325ms to run NodePressure ...
I0917 13:34:56.148053   88341 start.go:228] waiting for startup goroutines ...
I0917 13:34:56.240947   88341 out.go:177] üåü  Enabled addons: default-storageclass, storage-provisioner
I0917 13:34:56.251037   88341 addons.go:502] enable addons completed in 848.444375ms: enabled=[default-storageclass storage-provisioner]
I0917 13:34:56.251063   88341 start.go:233] waiting for cluster config update ...
I0917 13:34:56.251080   88341 start.go:242] writing updated cluster config ...
I0917 13:34:56.251933   88341 ssh_runner.go:195] Run: rm -f paused
I0917 13:34:56.393984   88341 start.go:600] kubectl: 1.28.2, cluster: 1.27.4 (minor skew: 1)
I0917 13:34:56.397995   88341 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Sep 17 11:34:44 minikube systemd[1]: Stopping Docker Application Container Engine...
Sep 17 11:34:44 minikube dockerd[571]: time="2023-09-17T11:34:44.865223630Z" level=info msg="Processing signal 'terminated'"
Sep 17 11:34:44 minikube dockerd[571]: time="2023-09-17T11:34:44.866221255Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Sep 17 11:34:44 minikube dockerd[571]: time="2023-09-17T11:34:44.866395796Z" level=info msg="Daemon shutdown complete"
Sep 17 11:34:44 minikube systemd[1]: docker.service: Deactivated successfully.
Sep 17 11:34:44 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 17 11:34:44 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 17 11:34:44 minikube dockerd[903]: time="2023-09-17T11:34:44.973722130Z" level=info msg="Starting up"
Sep 17 11:34:44 minikube dockerd[903]: time="2023-09-17T11:34:44.986555005Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Sep 17 11:34:44 minikube dockerd[903]: time="2023-09-17T11:34:44.988215213Z" level=info msg="Loading containers: start."
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.040518338Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.060768547Z" level=info msg="Loading containers: done."
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.072770547Z" level=info msg="Docker daemon" commit=4ffc614 graphdriver=overlay2 version=24.0.4
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.072809755Z" level=info msg="Daemon has completed initialization"
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.098242338Z" level=info msg="API listen on /var/run/docker.sock"
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.098312213Z" level=info msg="API listen on [::]:2376"
Sep 17 11:34:45 minikube systemd[1]: Started Docker Application Container Engine.
Sep 17 11:34:45 minikube systemd[1]: Stopping Docker Application Container Engine...
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.176985672Z" level=info msg="Processing signal 'terminated'"
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.177439880Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Sep 17 11:34:45 minikube dockerd[903]: time="2023-09-17T11:34:45.177561380Z" level=info msg="Daemon shutdown complete"
Sep 17 11:34:45 minikube systemd[1]: docker.service: Deactivated successfully.
Sep 17 11:34:45 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 17 11:34:45 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.213275713Z" level=info msg="Starting up"
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.219839088Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.224439755Z" level=info msg="Loading containers: start."
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.265025338Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.282202922Z" level=info msg="Loading containers: done."
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.287095713Z" level=info msg="Docker daemon" commit=4ffc614 graphdriver=overlay2 version=24.0.4
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.287126130Z" level=info msg="Daemon has completed initialization"
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.309802505Z" level=info msg="API listen on [::]:2376"
Sep 17 11:34:45 minikube dockerd[1104]: time="2023-09-17T11:34:45.309813338Z" level=info msg="API listen on /var/run/docker.sock"
Sep 17 11:34:45 minikube systemd[1]: Started Docker Application Container Engine.
Sep 17 11:34:45 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Start docker client with request timeout 0s"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Hairpin mode is set to hairpin-veth"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Loaded network plugin cni"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Docker cri networking managed by network plugin cni"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Docker Info: &{ID:f7f477cb-8d16-4271-a753-4f576787ca14 Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:8 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:24 OomKillDisable:false NGoroutines:35 SystemTime:2023-09-17T11:34:45.726993547Z LoggingDriver:json-file CgroupDriver:cgroupfs CgroupVersion:2 NEventsListener:0 KernelVersion:6.3.13-linuxkit OperatingSystem:Ubuntu 22.04.2 LTS OSVersion:22.04 OSType:linux Architecture:aarch64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0x40000be230 NCPU:4 MemTotal:4123820032 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy:control-plane.minikube.internal Name:minikube Labels:[provider=docker] ExperimentalBuild:false ServerVersion:24.0.4 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[] Shim:<nil>} runc:{Path:runc Args:[] Shim:<nil>}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:<nil> Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:3dce8eb055cbb6872793272b4f20ed16117344f8 Expected:3dce8eb055cbb6872793272b4f20ed16117344f8} RuncCommit:{ID:v1.1.7-0-g860f061 Expected:v1.1.7-0-g860f061} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=builtin name=cgroupns] ProductLicense: DefaultAddressPools:[] Warnings:[]}"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Setting cgroupDriver cgroupfs"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Sep 17 11:34:45 minikube cri-dockerd[1323]: time="2023-09-17T11:34:45Z" level=info msg="Start cri-dockerd grpc backend"
Sep 17 11:34:45 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Sep 17 11:34:49 minikube cri-dockerd[1323]: time="2023-09-17T11:34:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/9783e4840fbe2829454897366dc0c4e88b9b7b882911d2d82ef5eaf812662d21/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:34:49 minikube cri-dockerd[1323]: time="2023-09-17T11:34:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1f52b95782d7e9c69e2ba02c33723ca33c838cb57266c217d53f225e719e4f62/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:34:49 minikube cri-dockerd[1323]: time="2023-09-17T11:34:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/39378aeb5ef738a1bac9ea6b3546cb0d67eeedf4b8055d6aa658ed25925f2a79/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:34:49 minikube cri-dockerd[1323]: time="2023-09-17T11:34:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1f96c64a3c9d1f5a91382663830ecb4ee9e8cc280e0c7fc0e2968963e7b413e2/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:35:07 minikube cri-dockerd[1323]: time="2023-09-17T11:35:07Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/3023b16aff2f4262aada1764c44f7e256390e7413a969a5522e16959b0fc3091/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:35:08 minikube cri-dockerd[1323]: time="2023-09-17T11:35:08Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/5fe2ac88b589856498bbf51c909ce90a9d65e0db090e847b1c330d78719e688e/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:35:08 minikube cri-dockerd[1323]: time="2023-09-17T11:35:08Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/6274c52fadb32fc1181e226966db8168e50ee6e27d6c980d6f2efc0f6e66e449/resolv.conf as [nameserver 192.168.65.254 options ndots:0]"
Sep 17 11:35:15 minikube cri-dockerd[1323]: time="2023-09-17T11:35:15Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Sep 17 11:35:22 minikube cri-dockerd[1323]: time="2023-09-17T11:35:22Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/858e23353b415d6f41afd04febf0ae2c70df73a8407933e85d6ac2b1ed7e5f22/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 17 11:35:26 minikube cri-dockerd[1323]: time="2023-09-17T11:35:26Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2ed5c2b31270e4062d037ef54bd38578145955b1df7755b33ac0483c052ba990/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 17 11:35:34 minikube cri-dockerd[1323]: time="2023-09-17T11:35:34Z" level=info msg="Pulling image mongo:6.0: b18554fd2a27: Downloading [=======================================>           ]  160.6MB/204.4MB"
Sep 17 11:35:37 minikube dockerd[1104]: time="2023-09-17T11:35:37.844850168Z" level=info msg="ignoring event" container=6755f86539e73108b66629afce263c556f0a3b1c5a2bd2ab43d7bc33fd8ce0a8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 17 11:35:40 minikube cri-dockerd[1323]: time="2023-09-17T11:35:40Z" level=info msg="Stop pulling image mongo:6.0: Status: Downloaded newer image for mongo:6.0"
Sep 17 11:35:48 minikube cri-dockerd[1323]: time="2023-09-17T11:35:48Z" level=info msg="Stop pulling image nanajanashia/k8s-demo-app:v1.0: Status: Downloaded newer image for nanajanashia/k8s-demo-app:v1.0"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
3161c75fc13d9       nanajanashia/k8s-demo-app@sha256:6f554135da39ac00a1c2f43e44c2b0b54ca13d3d8044da969361e7781adb7f95   8 minutes ago       Running             webapp                    0                   2ed5c2b31270e       webapp-deployment-f8d7df85d-tmbqw
30349d0f25fa4       mongo@sha256:a6536338f3af7e50b5eec6bdddca6d9e9583fcb5fcbaf390136c7a165d31d284                       8 minutes ago       Running             mongodb                   0                   858e23353b415       mongo-deployment-77d5b4fd7c-pbhcd
a87b078dbc0b4       ba04bb24b9575                                                                                       8 minutes ago       Running             storage-provisioner       1                   3023b16aff2f4       storage-provisioner
5f3b439cf9d4a       97e04611ad434                                                                                       9 minutes ago       Running             coredns                   0                   6274c52fadb32       coredns-5d78c9869d-vqfmr
6c2df3f14e974       532e5a30e948f                                                                                       9 minutes ago       Running             kube-proxy                0                   5fe2ac88b5898       kube-proxy-gpc56
6755f86539e73       ba04bb24b9575                                                                                       9 minutes ago       Exited              storage-provisioner       0                   3023b16aff2f4       storage-provisioner
ddaf5aaa1f296       389f6f052cf83                                                                                       9 minutes ago       Running             kube-controller-manager   0                   39378aeb5ef73       kube-controller-manager-minikube
6f96c6be51472       24bc64e911039                                                                                       9 minutes ago       Running             etcd                      0                   1f96c64a3c9d1       etcd-minikube
824dbd3c2e368       6eb63895cb67f                                                                                       9 minutes ago       Running             kube-scheduler            0                   1f52b95782d7e       kube-scheduler-minikube
26c0dbb413f72       64aece92d6bde                                                                                       9 minutes ago       Running             kube-apiserver            0                   9783e4840fbe2       kube-apiserver-minikube

* 
* ==> coredns [5f3b439cf9d4] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = f869070685748660180df1b7a47d58cdafcf2f368266578c062d1151dc2c900964aecc5975e8882e6de6fdfb6460463e30ebfaad2ec8f0c3c6436f80225b3b5b
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:40966 - 56443 "HINFO IN 3378772539883110850.86363136160565111. udp 55 false 512" NXDOMAIN qr,rd,ra 55 2.594765209s
[INFO] 127.0.0.1:39113 - 15882 "HINFO IN 3378772539883110850.86363136160565111. udp 55 false 512" NXDOMAIN qr,rd,ra 55 0.005861333s
[INFO] 10.244.0.3:54925 - 52208 "A IN compass.mongodb.com.default.svc.cluster.local. udp 63 false 512" NXDOMAIN qr,aa,rd 156 0.0019415s
[INFO] 10.244.0.3:43621 - 44603 "A IN compass.mongodb.com.svc.cluster.local. udp 55 false 512" NXDOMAIN qr,aa,rd 148 0.000297333s
[INFO] 10.244.0.3:60962 - 24878 "A IN compass.mongodb.com.cluster.local. udp 51 false 512" NXDOMAIN qr,aa,rd 144 0.000060083s
[INFO] 10.244.0.3:58171 - 63473 "A IN api.segment.io.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000119958s
[INFO] 10.244.0.3:60333 - 9238 "A IN api.segment.io.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000646833s
[INFO] 10.244.0.3:54192 - 25290 "A IN api.segment.io.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000115625s
[INFO] 10.244.0.3:44714 - 4469 "A IN api.segment.io. udp 32 false 512" NOERROR qr,rd,ra 122 0.004118584s
[INFO] 10.244.0.3:57051 - 23629 "A IN compass.mongodb.com. udp 37 false 512" NOERROR qr,rd,ra 306 0.335875709s
[INFO] 10.244.0.3:40612 - 26765 "A IN api.segment.io.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000091916s
[INFO] 10.244.0.3:55866 - 21383 "A IN api.segment.io.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000032334s
[INFO] 10.244.0.3:43490 - 20542 "A IN api.segment.io.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000038458s
[INFO] 10.244.0.3:33593 - 48300 "A IN api.segment.io. udp 32 false 512" NOERROR qr,aa,rd,ra 122 0.000036833s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=fd7ecd9c4599bef9f04c0986c4a0187f98a4396e
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_09_17T13_34_55_0700
                    minikube.k8s.io/version=v1.31.2
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sun, 17 Sep 2023 11:34:52 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sun, 17 Sep 2023 11:44:15 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sun, 17 Sep 2023 11:41:03 +0000   Sun, 17 Sep 2023 11:34:50 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sun, 17 Sep 2023 11:41:03 +0000   Sun, 17 Sep 2023 11:34:50 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sun, 17 Sep 2023 11:41:03 +0000   Sun, 17 Sep 2023 11:34:50 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sun, 17 Sep 2023 11:41:03 +0000   Sun, 17 Sep 2023 11:34:52 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             4027168Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             4027168Ki
  pods:               110
System Info:
  Machine ID:                 10098600d8844c0e8be56d908ac4239a
  System UUID:                10098600d8844c0e8be56d908ac4239a
  Boot ID:                    cb112c1f-f13c-4043-8403-654ad5705e36
  Kernel Version:             6.3.13-linuxkit
  OS Image:                   Ubuntu 22.04.2 LTS
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://24.0.4
  Kubelet Version:            v1.27.4
  Kube-Proxy Version:         v1.27.4
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (9 in total)
  Namespace                   Name                                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                 ------------  ----------  ---------------  -------------  ---
  default                     mongo-deployment-77d5b4fd7c-pbhcd    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m54s
  default                     webapp-deployment-f8d7df85d-tmbqw    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         8m50s
  kube-system                 coredns-5d78c9869d-vqfmr             100m (2%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     9m8s
  kube-system                 etcd-minikube                        100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         9m20s
  kube-system                 kube-apiserver-minikube              250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m20s
  kube-system                 kube-controller-manager-minikube     200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m20s
  kube-system                 kube-proxy-gpc56                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m8s
  kube-system                 kube-scheduler-minikube              100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m20s
  kube-system                 storage-provisioner                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m19s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                750m (18%!)(MISSING)  0 (0%!)(MISSING)
  memory             170Mi (4%!)(MISSING)  170Mi (4%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age    From             Message
  ----    ------                   ----   ----             -------
  Normal  Starting                 9m7s   kube-proxy       
  Normal  Starting                 9m20s  kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  9m20s  kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  9m20s  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    9m20s  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     9m20s  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  RegisteredNode           9m8s   node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Sep17 10:34] cacheinfo: Unable to detect cache hierarchy for CPU 0
[  +0.001040] cacheinfo: Unable to detect cache hierarchy for CPU 1
[  +0.000363] cacheinfo: Unable to detect cache hierarchy for CPU 2
[  +0.000357] cacheinfo: Unable to detect cache hierarchy for CPU 3
[  +0.088339] cacheinfo: Unable to detect cache hierarchy for CPU 0
[  +0.016533] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[Sep17 10:35] memfd_create() without MFD_EXEC nor MFD_NOEXEC_SEAL, pid=207 '3'
[  +0.632649] FAT-fs (loop0): utf8 is not a recommended IO charset for FAT filesystems, filesystem will be case sensitive!
[  +0.003282] FAT-fs (loop0): utf8 is not a recommended IO charset for FAT filesystems, filesystem will be case sensitive!
[  +0.042513] grpcfuse: loading out-of-tree module taints kernel.
[Sep17 10:36] hrtimer: interrupt took 4832041 ns

* 
* ==> etcd [6f96c6be5147] <==
* {"level":"warn","ts":"2023-09-17T11:34:49.993Z","caller":"flags/flag.go:93","msg":"unrecognized environment variable","environment-variable":"ETCD_UNSUPPORTED_ARCH=arm64"}
{"level":"info","ts":"2023-09-17T11:34:49.994Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2023-09-17T11:34:49.995Z","caller":"embed/etcd.go:124","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2023-09-17T11:34:49.995Z","caller":"embed/etcd.go:484","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-09-17T11:34:49.995Z","caller":"embed/etcd.go:132","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2023-09-17T11:34:49.995Z","caller":"embed/etcd.go:306","msg":"starting an etcd server","etcd-version":"3.5.7","git-sha":"215b53cf3","go-version":"go1.17.13","go-os":"linux","go-arch":"arm64","max-cpu-set":4,"max-cpu-available":4,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://192.168.49.2:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-09-17T11:34:50.004Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"7.736625ms"}
{"level":"info","ts":"2023-09-17T11:34:50.026Z","caller":"etcdserver/raft.go:494","msg":"starting local member","local-member-id":"aec36adc501070cc","cluster-id":"fa54960ea34d58be"}
{"level":"info","ts":"2023-09-17T11:34:50.026Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2023-09-17T11:34:50.026Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 0"}
{"level":"info","ts":"2023-09-17T11:34:50.027Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2023-09-17T11:34:50.027Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 1"}
{"level":"info","ts":"2023-09-17T11:34:50.027Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"warn","ts":"2023-09-17T11:34:50.030Z","caller":"auth/store.go:1234","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-09-17T11:34:50.031Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2023-09-17T11:34:50.032Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-09-17T11:34:50.033Z","caller":"etcdserver/server.go:854","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.7","cluster-version":"to_be_decided"}
{"level":"info","ts":"2023-09-17T11:34:50.033Z","caller":"etcdserver/server.go:738","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-09-17T11:34:50.033Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2023-09-17T11:34:50.033Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2023-09-17T11:34:50.034Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2023-09-17T11:34:50.038Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2023-09-17T11:34:50.038Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2023-09-17T11:34:50.038Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-09-17T11:34:50.038Z","caller":"embed/etcd.go:275","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-09-17T11:34:50.038Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-09-17T11:34:50.039Z","caller":"embed/etcd.go:586","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-09-17T11:34:50.039Z","caller":"embed/etcd.go:558","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 1"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 1"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 1"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 2"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2023-09-17T11:34:50.428Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2023-09-17T11:34:50.429Z","caller":"etcdserver/server.go:2062","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2023-09-17T11:34:50.429Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-09-17T11:34:50.429Z","caller":"embed/serve.go:100","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-09-17T11:34:50.430Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2023-09-17T11:34:50.430Z","caller":"etcdserver/server.go:2571","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2023-09-17T11:34:50.430Z","caller":"embed/serve.go:198","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-09-17T11:34:50.430Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-09-17T11:34:50.440Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-09-17T11:34:50.434Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2023-09-17T11:34:50.440Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-09-17T11:34:50.440Z","caller":"etcdserver/server.go:2595","msg":"cluster version is updated","cluster-version":"3.5"}

* 
* ==> kernel <==
*  11:44:15 up  1:09,  0 users,  load average: 0.24, 0.46, 0.52
Linux minikube 6.3.13-linuxkit #1 SMP PREEMPT Thu Sep  7 07:48:47 UTC 2023 aarch64 aarch64 aarch64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.2 LTS"

* 
* ==> kube-apiserver [26c0dbb413f7] <==
* I0917 11:34:52.061252       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0917 11:34:52.061319       1 shared_informer.go:311] Waiting for caches to sync for cluster_authentication_trust_controller
I0917 11:34:52.061398       1 apf_controller.go:361] Starting API Priority and Fairness config controller
I0917 11:34:52.061542       1 customresource_discovery_controller.go:289] Starting DiscoveryController
I0917 11:34:52.061610       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0917 11:34:52.061760       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0917 11:34:52.061843       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0917 11:34:52.061912       1 handler_discovery.go:392] Starting ResourceDiscoveryManager
I0917 11:34:52.061996       1 system_namespaces_controller.go:67] Starting system namespaces controller
I0917 11:34:52.062158       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0917 11:34:52.062627       1 controller.go:121] Starting legacy_token_tracking_controller
I0917 11:34:52.062786       1 shared_informer.go:311] Waiting for caches to sync for configmaps
I0917 11:34:52.063003       1 aggregator.go:150] waiting for initial CRD sync...
I0917 11:34:52.063041       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0917 11:34:52.063256       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0917 11:34:52.063478       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0917 11:34:52.061308       1 available_controller.go:423] Starting AvailableConditionController
I0917 11:34:52.063768       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0917 11:34:52.064385       1 controller.go:85] Starting OpenAPI controller
I0917 11:34:52.064731       1 controller.go:85] Starting OpenAPI V3 controller
I0917 11:34:52.064919       1 naming_controller.go:291] Starting NamingConditionController
I0917 11:34:52.065100       1 establishing_controller.go:76] Starting EstablishingController
I0917 11:34:52.065325       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0917 11:34:52.065473       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0917 11:34:52.065629       1 crd_finalizer.go:266] Starting CRDFinalizer
I0917 11:34:52.075272       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0917 11:34:52.075520       1 shared_informer.go:311] Waiting for caches to sync for crd-autoregister
I0917 11:34:52.187686       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0917 11:34:52.187799       1 shared_informer.go:318] Caches are synced for crd-autoregister
I0917 11:34:52.187829       1 shared_informer.go:318] Caches are synced for cluster_authentication_trust_controller
I0917 11:34:52.187849       1 apf_controller.go:366] Running API Priority and Fairness config worker
I0917 11:34:52.187866       1 apf_controller.go:369] Running API Priority and Fairness periodic rebalancing process
I0917 11:34:52.187925       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0917 11:34:52.188079       1 shared_informer.go:318] Caches are synced for configmaps
I0917 11:34:52.187855       1 aggregator.go:152] initial CRD sync complete...
I0917 11:34:52.188425       1 autoregister_controller.go:141] Starting autoregister controller
I0917 11:34:52.188432       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0917 11:34:52.188436       1 cache.go:39] Caches are synced for autoregister controller
I0917 11:34:52.188881       1 controller.go:624] quota admission added evaluator for: namespaces
E0917 11:34:52.189828       1 controller.go:146] "Failed to ensure lease exists, will retry" err="namespaces \"kube-system\" not found" interval="200ms"
I0917 11:34:52.217728       1 shared_informer.go:318] Caches are synced for node_authorizer
I0917 11:34:52.393298       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I0917 11:34:52.897838       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0917 11:34:53.073208       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0917 11:34:53.079389       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0917 11:34:53.079423       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0917 11:34:53.260284       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0917 11:34:53.275257       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0917 11:34:53.327277       1 alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W0917 11:34:53.330499       1 lease.go:251] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I0917 11:34:53.331240       1 controller.go:624] quota admission added evaluator for: endpoints
I0917 11:34:53.333520       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0917 11:34:54.127883       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I0917 11:34:55.075855       1 controller.go:624] quota admission added evaluator for: deployments.apps
I0917 11:34:55.091874       1 alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I0917 11:34:55.097487       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I0917 11:35:07.592009       1 controller.go:624] quota admission added evaluator for: controllerrevisions.apps
I0917 11:35:07.638726       1 controller.go:624] quota admission added evaluator for: replicasets.apps
I0917 11:35:21.708697       1 alloc.go:330] "allocated clusterIPs" service="default/mongo-service" clusterIPs=map[IPv4:10.104.6.65]
I0917 11:35:25.817330       1 alloc.go:330] "allocated clusterIPs" service="default/webapp-service" clusterIPs=map[IPv4:10.100.212.19]

* 
* ==> kube-controller-manager [ddaf5aaa1f29] <==
* I0917 11:35:07.217435       1 shared_informer.go:311] Waiting for caches to sync for TTL after finished
I0917 11:35:07.220465       1 shared_informer.go:311] Waiting for caches to sync for resource quota
I0917 11:35:07.231472       1 shared_informer.go:318] Caches are synced for ephemeral
I0917 11:35:07.235708       1 shared_informer.go:318] Caches are synced for PVC protection
I0917 11:35:07.237978       1 actual_state_of_world.go:547] "Failed to update statusUpdateNeeded field in actual state of world" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0917 11:35:07.238878       1 shared_informer.go:311] Waiting for caches to sync for garbage collector
I0917 11:35:07.244106       1 shared_informer.go:318] Caches are synced for namespace
I0917 11:35:07.247688       1 shared_informer.go:318] Caches are synced for service account
I0917 11:35:07.261603       1 shared_informer.go:318] Caches are synced for node
I0917 11:35:07.261646       1 range_allocator.go:174] "Sending events to api server"
I0917 11:35:07.261656       1 range_allocator.go:178] "Starting range CIDR allocator"
I0917 11:35:07.261658       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I0917 11:35:07.261661       1 shared_informer.go:318] Caches are synced for cidrallocator
I0917 11:35:07.265181       1 range_allocator.go:380] "Set node PodCIDR" node="minikube" podCIDRs=[10.244.0.0/24]
I0917 11:35:07.271929       1 shared_informer.go:318] Caches are synced for stateful set
I0917 11:35:07.277086       1 shared_informer.go:318] Caches are synced for expand
I0917 11:35:07.277103       1 shared_informer.go:318] Caches are synced for endpoint_slice
I0917 11:35:07.279038       1 shared_informer.go:318] Caches are synced for disruption
I0917 11:35:07.282893       1 shared_informer.go:318] Caches are synced for taint
I0917 11:35:07.283084       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0917 11:35:07.283107       1 taint_manager.go:211] "Sending events to api server"
I0917 11:35:07.283370       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-serving
I0917 11:35:07.283502       1 node_lifecycle_controller.go:1223] "Initializing eviction metric for zone" zone=""
I0917 11:35:07.283820       1 node_lifecycle_controller.go:875] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I0917 11:35:07.283864       1 node_lifecycle_controller.go:1069] "Controller detected that zone is now in new state" zone="" newState=Normal
I0917 11:35:07.286031       1 shared_informer.go:318] Caches are synced for ReplicaSet
I0917 11:35:07.286589       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0917 11:35:07.287657       1 shared_informer.go:318] Caches are synced for ClusterRoleAggregator
I0917 11:35:07.287734       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-legacy-unknown
I0917 11:35:07.287920       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0917 11:35:07.287925       1 shared_informer.go:318] Caches are synced for crt configmap
I0917 11:35:07.287979       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-client
I0917 11:35:07.289279       1 shared_informer.go:318] Caches are synced for daemon sets
I0917 11:35:07.293524       1 shared_informer.go:318] Caches are synced for PV protection
I0917 11:35:07.300303       1 shared_informer.go:318] Caches are synced for ReplicationController
I0917 11:35:07.305037       1 shared_informer.go:318] Caches are synced for deployment
I0917 11:35:07.307037       1 shared_informer.go:318] Caches are synced for certificate-csrapproving
I0917 11:35:07.312962       1 shared_informer.go:318] Caches are synced for attach detach
I0917 11:35:07.317650       1 shared_informer.go:318] Caches are synced for TTL after finished
I0917 11:35:07.326020       1 shared_informer.go:318] Caches are synced for job
I0917 11:35:07.328575       1 shared_informer.go:318] Caches are synced for persistent volume
I0917 11:35:07.330015       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I0917 11:35:07.330396       1 shared_informer.go:318] Caches are synced for GC
I0917 11:35:07.330406       1 shared_informer.go:318] Caches are synced for TTL
I0917 11:35:07.369258       1 shared_informer.go:318] Caches are synced for HPA
I0917 11:35:07.375589       1 shared_informer.go:318] Caches are synced for cronjob
I0917 11:35:07.399929       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I0917 11:35:07.428587       1 shared_informer.go:318] Caches are synced for endpoint
I0917 11:35:07.500431       1 shared_informer.go:318] Caches are synced for resource quota
I0917 11:35:07.521291       1 shared_informer.go:318] Caches are synced for resource quota
I0917 11:35:07.600319       1 event.go:307] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-gpc56"
I0917 11:35:07.641405       1 event.go:307] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-5d78c9869d to 1"
I0917 11:35:07.841704       1 shared_informer.go:318] Caches are synced for garbage collector
I0917 11:35:07.855703       1 shared_informer.go:318] Caches are synced for garbage collector
I0917 11:35:07.855744       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I0917 11:35:07.992369       1 event.go:307] "Event occurred" object="kube-system/coredns-5d78c9869d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-5d78c9869d-vqfmr"
I0917 11:35:21.702881       1 event.go:307] "Event occurred" object="default/mongo-deployment" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set mongo-deployment-77d5b4fd7c to 1"
I0917 11:35:21.723019       1 event.go:307] "Event occurred" object="default/mongo-deployment-77d5b4fd7c" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: mongo-deployment-77d5b4fd7c-pbhcd"
I0917 11:35:25.803372       1 event.go:307] "Event occurred" object="default/webapp-deployment" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set webapp-deployment-f8d7df85d to 1"
I0917 11:35:25.823977       1 event.go:307] "Event occurred" object="default/webapp-deployment-f8d7df85d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: webapp-deployment-f8d7df85d-tmbqw"

* 
* ==> kube-proxy [6c2df3f14e97] <==
* I0917 11:35:08.118542       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0917 11:35:08.118630       1 server_others.go:110] "Detected node IP" address="192.168.49.2"
I0917 11:35:08.118670       1 server_others.go:554] "Using iptables proxy"
I0917 11:35:08.133910       1 server_others.go:192] "Using iptables Proxier"
I0917 11:35:08.133957       1 server_others.go:199] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0917 11:35:08.133966       1 server_others.go:200] "Creating dualStackProxier for iptables"
I0917 11:35:08.133983       1 server_others.go:484] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, defaulting to no-op detect-local for IPv6"
I0917 11:35:08.134346       1 proxier.go:253] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0917 11:35:08.136126       1 server.go:658] "Version info" version="v1.27.4"
I0917 11:35:08.136205       1 server.go:660] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0917 11:35:08.138509       1 config.go:188] "Starting service config controller"
I0917 11:35:08.138659       1 shared_informer.go:311] Waiting for caches to sync for service config
I0917 11:35:08.138707       1 config.go:97] "Starting endpoint slice config controller"
I0917 11:35:08.138714       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0917 11:35:08.139291       1 config.go:315] "Starting node config controller"
I0917 11:35:08.139300       1 shared_informer.go:311] Waiting for caches to sync for node config
I0917 11:35:08.239514       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0917 11:35:08.239533       1 shared_informer.go:318] Caches are synced for service config
I0917 11:35:08.239543       1 shared_informer.go:318] Caches are synced for node config

* 
* ==> kube-scheduler [824dbd3c2e36] <==
* I0917 11:34:50.794029       1 serving.go:348] Generated self-signed cert in-memory
W0917 11:34:52.093229       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0917 11:34:52.093404       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0917 11:34:52.093430       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0917 11:34:52.093470       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0917 11:34:52.116653       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.27.4"
I0917 11:34:52.116675       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0917 11:34:52.117759       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0917 11:34:52.117848       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0917 11:34:52.118032       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0917 11:34:52.118072       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
W0917 11:34:52.128879       1 reflector.go:533] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0917 11:34:52.128911       1 reflector.go:148] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0917 11:34:52.129140       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0917 11:34:52.129145       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0917 11:34:52.129168       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0917 11:34:52.129174       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0917 11:34:52.129195       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0917 11:34:52.129199       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0917 11:34:52.129213       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0917 11:34:52.129217       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0917 11:34:52.129233       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0917 11:34:52.129236       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0917 11:34:52.129256       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0917 11:34:52.129260       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0917 11:34:52.129315       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0917 11:34:52.129325       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0917 11:34:52.129349       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0917 11:34:52.129353       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0917 11:34:52.129381       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0917 11:34:52.129387       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0917 11:34:52.129402       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0917 11:34:52.129405       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0917 11:34:52.129428       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0917 11:34:52.129431       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0917 11:34:52.130841       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0917 11:34:52.130873       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0917 11:34:52.132315       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0917 11:34:52.132339       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0917 11:34:52.132346       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0917 11:34:52.132354       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0917 11:34:53.009185       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0917 11:34:53.009339       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0917 11:34:53.163726       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0917 11:34:53.163751       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0917 11:34:53.169464       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0917 11:34:53.169483       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0917 11:34:53.178164       1 reflector.go:533] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0917 11:34:53.178216       1 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
I0917 11:34:53.618252       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.207603    2379 state_mem.go:35] "Initializing new in-memory state store"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.207727    2379 state_mem.go:75] "Updated machine memory state"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.208294    2379 manager.go:455] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.208475    2379 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.264639    2379 kubelet_node_status.go:70] "Attempting to register node" node="minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.267054    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.267317    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.267368    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.267392    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.276846    2379 kubelet_node_status.go:108] "Node was previously registered" node="minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.276905    2379 kubelet_node_status.go:73] "Successfully registered node" node="minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360123    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/eb675835e10503c79265cf0e2983f93c-kubeconfig\") pod \"kube-scheduler-minikube\" (UID: \"eb675835e10503c79265cf0e2983f93c\") " pod="kube-system/kube-scheduler-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360169    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/8af0e85a28544808d52bb7c47ad824ed-etcd-certs\") pod \"etcd-minikube\" (UID: \"8af0e85a28544808d52bb7c47ad824ed\") " pod="kube-system/etcd-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360189    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/f241819aff4d77a34fc71bea1fac9af8-usr-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"f241819aff4d77a34fc71bea1fac9af8\") " pod="kube-system/kube-apiserver-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360211    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-ca-certs\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360229    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-etc-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360273    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-usr-local-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360338    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/f241819aff4d77a34fc71bea1fac9af8-k8s-certs\") pod \"kube-apiserver-minikube\" (UID: \"f241819aff4d77a34fc71bea1fac9af8\") " pod="kube-system/kube-apiserver-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360365    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-flexvolume-dir\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360384    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-k8s-certs\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360419    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-usr-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360439    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/f241819aff4d77a34fc71bea1fac9af8-usr-local-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"f241819aff4d77a34fc71bea1fac9af8\") " pod="kube-system/kube-apiserver-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360499    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/b3702ceb912504d37098b922ccdcfa41-kubeconfig\") pod \"kube-controller-manager-minikube\" (UID: \"b3702ceb912504d37098b922ccdcfa41\") " pod="kube-system/kube-controller-manager-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360515    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/f241819aff4d77a34fc71bea1fac9af8-ca-certs\") pod \"kube-apiserver-minikube\" (UID: \"f241819aff4d77a34fc71bea1fac9af8\") " pod="kube-system/kube-apiserver-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360538    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/f241819aff4d77a34fc71bea1fac9af8-etc-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"f241819aff4d77a34fc71bea1fac9af8\") " pod="kube-system/kube-apiserver-minikube"
Sep 17 11:34:55 minikube kubelet[2379]: I0917 11:34:55.360558    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/8af0e85a28544808d52bb7c47ad824ed-etcd-data\") pod \"etcd-minikube\" (UID: \"8af0e85a28544808d52bb7c47ad824ed\") " pod="kube-system/etcd-minikube"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.146065    2379 apiserver.go:52] "Watching apiserver"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.158918    2379 desired_state_of_world_populator.go:153] "Finished populating initial desired state of world"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.188279    2379 reconciler.go:41] "Reconciler: start to sync state"
Sep 17 11:34:56 minikube kubelet[2379]: E0917 11:34:56.206596    2379 kubelet.go:1856] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.218218    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-apiserver-minikube" podStartSLOduration=1.218173302 podCreationTimestamp="2023-09-17 11:34:55 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:34:56.217999094 +0000 UTC m=+1.171124627" watchObservedRunningTime="2023-09-17 11:34:56.218173302 +0000 UTC m=+1.171298877"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.218278    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-scheduler-minikube" podStartSLOduration=1.218269844 podCreationTimestamp="2023-09-17 11:34:55 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:34:56.21288451 +0000 UTC m=+1.166010085" watchObservedRunningTime="2023-09-17 11:34:56.218269844 +0000 UTC m=+1.171395418"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.222813    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/etcd-minikube" podStartSLOduration=1.222788552 podCreationTimestamp="2023-09-17 11:34:55 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:34:56.222653885 +0000 UTC m=+1.175779460" watchObservedRunningTime="2023-09-17 11:34:56.222788552 +0000 UTC m=+1.175914127"
Sep 17 11:34:56 minikube kubelet[2379]: I0917 11:34:56.227188    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-controller-manager-minikube" podStartSLOduration=1.227161135 podCreationTimestamp="2023-09-17 11:34:55 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:34:56.22698851 +0000 UTC m=+1.180114085" watchObservedRunningTime="2023-09-17 11:34:56.227161135 +0000 UTC m=+1.180286668"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.305033    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.389355    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-56kp9\" (UniqueName: \"kubernetes.io/projected/22d85294-6222-41e7-95d0-a77bf5fadf87-kube-api-access-56kp9\") pod \"storage-provisioner\" (UID: \"22d85294-6222-41e7-95d0-a77bf5fadf87\") " pod="kube-system/storage-provisioner"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.389412    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/host-path/22d85294-6222-41e7-95d0-a77bf5fadf87-tmp\") pod \"storage-provisioner\" (UID: \"22d85294-6222-41e7-95d0-a77bf5fadf87\") " pod="kube-system/storage-provisioner"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.604872    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.691522    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/1cf180dc-cf6c-4277-8f09-b1720fa54dcc-kube-proxy\") pod \"kube-proxy-gpc56\" (UID: \"1cf180dc-cf6c-4277-8f09-b1720fa54dcc\") " pod="kube-system/kube-proxy-gpc56"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.691559    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/1cf180dc-cf6c-4277-8f09-b1720fa54dcc-xtables-lock\") pod \"kube-proxy-gpc56\" (UID: \"1cf180dc-cf6c-4277-8f09-b1720fa54dcc\") " pod="kube-system/kube-proxy-gpc56"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.691574    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-796bg\" (UniqueName: \"kubernetes.io/projected/1cf180dc-cf6c-4277-8f09-b1720fa54dcc-kube-api-access-796bg\") pod \"kube-proxy-gpc56\" (UID: \"1cf180dc-cf6c-4277-8f09-b1720fa54dcc\") " pod="kube-system/kube-proxy-gpc56"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.691594    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/1cf180dc-cf6c-4277-8f09-b1720fa54dcc-lib-modules\") pod \"kube-proxy-gpc56\" (UID: \"1cf180dc-cf6c-4277-8f09-b1720fa54dcc\") " pod="kube-system/kube-proxy-gpc56"
Sep 17 11:35:07 minikube kubelet[2379]: I0917 11:35:07.995038    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:35:08 minikube kubelet[2379]: I0917 11:35:08.093652    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-plv9k\" (UniqueName: \"kubernetes.io/projected/198d2a1a-8840-4e98-af5a-15340177723b-kube-api-access-plv9k\") pod \"coredns-5d78c9869d-vqfmr\" (UID: \"198d2a1a-8840-4e98-af5a-15340177723b\") " pod="kube-system/coredns-5d78c9869d-vqfmr"
Sep 17 11:35:08 minikube kubelet[2379]: I0917 11:35:08.093690    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/198d2a1a-8840-4e98-af5a-15340177723b-config-volume\") pod \"coredns-5d78c9869d-vqfmr\" (UID: \"198d2a1a-8840-4e98-af5a-15340177723b\") " pod="kube-system/coredns-5d78c9869d-vqfmr"
Sep 17 11:35:08 minikube kubelet[2379]: I0917 11:35:08.323563    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-gpc56" podStartSLOduration=1.323474835 podCreationTimestamp="2023-09-17 11:35:07 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:35:08.32316946 +0000 UTC m=+13.277992382" watchObservedRunningTime="2023-09-17 11:35:08.323474835 +0000 UTC m=+13.278297757"
Sep 17 11:35:09 minikube kubelet[2379]: I0917 11:35:09.363384    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/storage-provisioner" podStartSLOduration=13.363325502 podCreationTimestamp="2023-09-17 11:34:56 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:35:08.334171918 +0000 UTC m=+13.288994798" watchObservedRunningTime="2023-09-17 11:35:09.363325502 +0000 UTC m=+14.318149049"
Sep 17 11:35:09 minikube kubelet[2379]: I0917 11:35:09.375741    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-5d78c9869d-vqfmr" podStartSLOduration=2.375703419 podCreationTimestamp="2023-09-17 11:35:07 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2023-09-17 11:35:09.364136586 +0000 UTC m=+14.318959674" watchObservedRunningTime="2023-09-17 11:35:09.375703419 +0000 UTC m=+14.330526341"
Sep 17 11:35:15 minikube kubelet[2379]: I0917 11:35:15.577715    2379 kuberuntime_manager.go:1460] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Sep 17 11:35:15 minikube kubelet[2379]: I0917 11:35:15.580971    2379 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Sep 17 11:35:21 minikube kubelet[2379]: I0917 11:35:21.730949    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:35:21 minikube kubelet[2379]: I0917 11:35:21.924617    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vwz8h\" (UniqueName: \"kubernetes.io/projected/728bcaa7-7e64-47e2-994d-3640e2c74273-kube-api-access-vwz8h\") pod \"mongo-deployment-77d5b4fd7c-pbhcd\" (UID: \"728bcaa7-7e64-47e2-994d-3640e2c74273\") " pod="default/mongo-deployment-77d5b4fd7c-pbhcd"
Sep 17 11:35:22 minikube kubelet[2379]: I0917 11:35:22.534169    2379 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="858e23353b415d6f41afd04febf0ae2c70df73a8407933e85d6ac2b1ed7e5f22"
Sep 17 11:35:25 minikube kubelet[2379]: I0917 11:35:25.831608    2379 topology_manager.go:212] "Topology Admit Handler"
Sep 17 11:35:25 minikube kubelet[2379]: I0917 11:35:25.984601    2379 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-jkjs4\" (UniqueName: \"kubernetes.io/projected/49567899-4a6f-4570-a35f-a29e7ebe6da3-kube-api-access-jkjs4\") pod \"webapp-deployment-f8d7df85d-tmbqw\" (UID: \"49567899-4a6f-4570-a35f-a29e7ebe6da3\") " pod="default/webapp-deployment-f8d7df85d-tmbqw"
Sep 17 11:35:38 minikube kubelet[2379]: I0917 11:35:38.716087    2379 scope.go:115] "RemoveContainer" containerID="6755f86539e73108b66629afce263c556f0a3b1c5a2bd2ab43d7bc33fd8ce0a8"
Sep 17 11:35:49 minikube kubelet[2379]: I0917 11:35:49.895004    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="default/webapp-deployment-f8d7df85d-tmbqw" podStartSLOduration=2.412466706 podCreationTimestamp="2023-09-17 11:35:25 +0000 UTC" firstStartedPulling="2023-09-17 11:35:26.286120719 +0000 UTC m=+31.240943640" lastFinishedPulling="2023-09-17 11:35:48.767195923 +0000 UTC m=+53.723336275" observedRunningTime="2023-09-17 11:35:49.892495507 +0000 UTC m=+54.848635859" watchObservedRunningTime="2023-09-17 11:35:49.894859341 +0000 UTC m=+54.850999734"
Sep 17 11:35:49 minikube kubelet[2379]: I0917 11:35:49.895387    2379 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="default/mongo-deployment-77d5b4fd7c-pbhcd" podStartSLOduration=11.071808125 podCreationTimestamp="2023-09-17 11:35:21 +0000 UTC" firstStartedPulling="2023-09-17 11:35:22.5620433 +0000 UTC m=+27.516866222" lastFinishedPulling="2023-09-17 11:35:40.384290753 +0000 UTC m=+45.340431146" observedRunningTime="2023-09-17 11:35:40.747746211 +0000 UTC m=+45.703886605" watchObservedRunningTime="2023-09-17 11:35:49.895373049 +0000 UTC m=+54.851513442"
Sep 17 11:39:55 minikube kubelet[2379]: W0917 11:39:55.200488    2379 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Sep 17 11:39:55 minikube kubelet[2379]: W0917 11:39:55.202855    2379 machine.go:65] Cannot read vendor id correctly, set empty.

* 
* ==> storage-provisioner [6755f86539e7] <==
* I0917 11:35:07.797795       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0917 11:35:37.800174       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout

* 
* ==> storage-provisioner [a87b078dbc0b] <==
* I0917 11:35:39.021007       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0917 11:35:39.029102       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0917 11:35:39.029176       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0917 11:35:39.037296       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0917 11:35:39.037437       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_04cf54be-3f5a-4e3a-87c0-f1bb56adc26d!
I0917 11:35:39.037401       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"7482f4d0-bcd6-4f17-a892-ec9da3f393d8", APIVersion:"v1", ResourceVersion:"421", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_04cf54be-3f5a-4e3a-87c0-f1bb56adc26d became leader
I0917 11:35:39.138370       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_04cf54be-3f5a-4e3a-87c0-f1bb56adc26d!

